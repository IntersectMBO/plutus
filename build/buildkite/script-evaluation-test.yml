# A nightly job which downloads script evaluation dumps from S3 and runs a regression test.
steps:
  - label: "Download and unzip dump files"
    command: |
      nix-shell --run 'LOCAL_DIR=$HOME/mainnet-script-dump-downloaded ./scripts/s3-sync-unzip.sh s3://plutus/mainnet-script-dump/ *.event.bz2'
#     TODO(std) check that this works 
#     nix develop --command 'LOCAL_DIR=$HOME/mainnet-script-dump-downloaded ./scripts/s3-sync-unzip.sh s3://plutus/mainnet-script-dump/ *.event.bz2'
    concurrency: 1
    concurrency_group: "plutus-script-evaluation"
    agents:
      queue: "plutus"
  - wait
  - label: "Script evaluation test"
    # Run the test cases sequentially. This ensures we don't need to simultaneously store
    # multiple `ScriptEvaluationEvents`, which are large, in memory. Each test case
    # contains many script evaluation events, and those are run in parallel based on
    # the number of available processors.
    command: |
      nix-shell --run 'cabal update && EVENT_DUMP_DIR=$HOME/mainnet-script-dump-downloaded cabal v2-run plutus-ledger-api:evaluation-test -- --num-threads=1'
#     TODO(std) check that this works 
#     nix develop --command 'cabal update && EVENT_DUMP_DIR=$HOME/mainnet-script-dump-downloaded cabal v2-run plutus-ledger-api:evaluation-test -- --num-threads=1'
    concurrency: 1
    concurrency_group: "plutus-script-evaluation"
    agents:
      queue: "plutus"
